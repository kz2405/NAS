{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7481b84",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5115a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import q_learner as q_learner\n",
    "import state_string_utils as stringutils\n",
    "import state_enumerator as stateenum\n",
    "import NAS \n",
    "import netparser\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "import importlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7479f6e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db546748",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_window = 90\n",
    "\n",
    "# performance measures window: number of years\n",
    "pm_window = 3\n",
    "lb_window = int(3 * pm_window * 365.25) + 1\n",
    "\n",
    "# Window length between training samples: number of days\n",
    "sample_window = 30\n",
    "\n",
    "# test period start\n",
    "test_start_date = '2020-06-30'\n",
    "\n",
    "# filepath\n",
    "filepath = '/Users/kz_ke/Documents/Masters/Classes/DL/WM-SecuritySelection-main/data/MF_LargeCap_ExcessReturn_3Y.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b49e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_er_ari(filepath, label_window=pm_window):\n",
    "    er_ari_df = pd.read_parquet(filepath)\n",
    "    \n",
    "\n",
    "    data_dict = {ticker: er_ari_df[ticker].dropna() for ticker in er_ari_df.columns}\n",
    "    tickers_to_remove = []\n",
    "    \n",
    "    label_dict = {}\n",
    "    for ticker, series in tqdm(data_dict.items()):\n",
    "        if series.isna().sum() == series.shape[0]:\n",
    "            tickers_to_remove += [ticker]\n",
    "            continue\n",
    "\n",
    "        last_date = series.index[-1] - relativedelta(years=pm_window)\n",
    "        if last_date <= series.index[0]:\n",
    "            tickers_to_remove.append(ticker)\n",
    "            continue\n",
    "\n",
    "        index = series.loc[:series.index[-1] - relativedelta(years=pm_window)].index\n",
    "        label_dict[ticker] = pd.Series([\n",
    "            series[date + relativedelta(years=pm_window)] for date in index\n",
    "        ], index=index)\n",
    "        \n",
    "    _ = [data_dict.pop(ticker) for ticker in tickers_to_remove]\n",
    "    \n",
    "    return data_dict, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0749db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1330/1330 [05:05<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dict, label_dict = prepare_data_for_er_ari(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee096aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1130/1130 [00:08<00:00, 127.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tickers = list(data_dict.keys())\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "# test start date\n",
    "checkpoint = datetime.strptime(test_start_date, '%Y-%m-%d') - relativedelta(years=pm_window)\n",
    "\n",
    "for ticker in tqdm(tickers):    \n",
    "    label = label_dict[ticker]\n",
    "    if label.shape[0] == 0:\n",
    "        continue\n",
    "    ts = data_dict[ticker].loc[:label.index[-1]]\n",
    "\n",
    "    indices = [np.arange(i, i+lb_window, feat_window) for i in range(0, ts.shape[0] - lb_window + 1, sample_window)]\n",
    "    \n",
    "    temp_data = np.array([ts.iloc[sub_indices].values for sub_indices in indices])\n",
    "    if temp_data.shape[0] == 0:\n",
    "        continue\n",
    "    temp_labels = np.array([label.loc[ts.index[sub_indices[-1]]] for sub_indices in indices])\n",
    "    \n",
    "    train_indices = [idx for idx in range(temp_data.shape[0]) if ts.index[indices[idx][-1]] <= checkpoint]\n",
    "    test_indices = [idx for idx in range(temp_data.shape[0]) if ts.index[indices[idx][-1]] > checkpoint]\n",
    "    \n",
    "    train_data += [temp_data[train_indices]] \n",
    "    train_labels += [temp_labels[train_indices]]\n",
    "    \n",
    "    test_data += [temp_data[test_indices]] \n",
    "    test_labels += [temp_labels[test_indices]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51566c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_input_data(x=None, y=None):\n",
    "    if x is not None:\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.reshape(-1, 1, x.shape[1])\n",
    "        elif len(x.shape) == 3:\n",
    "            x = x.reshape(-1, x.shape[2], x.shape[1])\n",
    "        else:\n",
    "            raise ValueError('Invalid x shape: {}'.format(x.shape))\n",
    "\n",
    "    if y is not None:\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        elif len(y.shape) == 2:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Invalid y shape: {}'.format(y.shape))\n",
    "\n",
    "    if x is None and y is None:\n",
    "        return None\n",
    "    elif x is None and y is not None:\n",
    "        return y\n",
    "    elif x is not None and y is None:\n",
    "        return x\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e21c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = np.concatenate(train_data)[:, np.newaxis, :]\n",
    "y_train = np.concatenate(train_labels)[:, np.newaxis]\n",
    "\n",
    "x_test = np.concatenate(test_data)[:, np.newaxis, :]\n",
    "y_test = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d73a9",
   "metadata": {},
   "source": [
    "## Running NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eab1a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/kz_ke/Documents/Masters/Classes/DL/AutoML3/mylogs'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "    print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83eee0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = __import__('models.AutoML',\n",
    "                    globals(),\n",
    "                    locals(),\n",
    "                    ['state_space_parameters', 'hyper_parameters'], \n",
    "                    0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf2b3f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "factory = NAS.NAS('mylogs',\n",
    "                  _model.state_space_parameters,\n",
    "                  _model.hyper_parameters,\n",
    "                  1,\n",
    "                  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ba7195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM(150,tanh), LSTM(200,leaky_relu), FC(200, sigmoid), D(0.200000), FC(1, linear)]\n",
      "Epoch 1/10\n",
      "95/95 [==============================] - 5s 33ms/step - loss: 0.1150 - root_mean_squared_error: 0.3392\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.1079 - root_mean_squared_error: 0.3284: 2s - loss: \n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 3s 37ms/step - loss: 0.0979 - root_mean_squared_error: 0.3129\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 4s 38ms/step - loss: 0.0879 - root_mean_squared_error: 0.2964\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.0674 - root_mean_squared_error: 0.2595\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.0409 - root_mean_squared_error: 0.2023\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.0211 - root_mean_squared_error: 0.1454\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.0110 - root_mean_squared_error: 0.1048\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 3s 35ms/step - loss: 0.0064 - root_mean_squared_error: 0.0803\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.0043 - root_mean_squared_error: 0.0653\n",
      "328/328 [==============================] - 2s 3ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712\n",
      "Incorporated net, acc: 0.071235, net: [LSTM(150,tanh), LSTM(200,leaky_relu), FC(200, sigmoid), D(0.200000), FC(1, linear)]\n"
     ]
    }
   ],
   "source": [
    "net, i = factory.generate_new_netork()\n",
    "print(net)\n",
    "p= netparser.parse('net', net)\n",
    "newnet = netparser.parse_network_structure(p)\n",
    "model = keras.Sequential(newnet)\n",
    "\n",
    "#callback = keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3, restore_best_weights = True)\n",
    "#model.compile(\n",
    "#            optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "#            loss='categorical_crossentropy',\n",
    "#            metrics=[keras.metrics.CategoricalAccuracy()]\n",
    "#        )\n",
    "model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "model.build(input_shape=(None, None, x_train.shape[-1]))\n",
    "\n",
    "#history = model.fit(x_train, y_train, batch_size = 40, epochs =1, callbacks=[callback], validation_data=(x_valid, y_valid))\n",
    "model.fit(x_train, y_train, batch_size = 500, epochs =10)\n",
    "\n",
    "bestval = model.evaluate(x_test, y_test)[1]\n",
    "\n",
    "factory.incorporate_trained_net(net, bestval, 1, [i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd225b",
   "metadata": {},
   "source": [
    "## Step by Step Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac96cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[LSTM(100,sigmoid), FC(200, leaky_relu), D(0.100000), FC(1, leaky_relu)]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, i = factory.generate_new_netork()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e3b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "p= netparser.parse('net', net)\n",
    "newnet = netparser.parse_network_structure(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1249a65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.recurrent_v2.LSTM at 0x1963f4ff760>,\n",
       " <keras.layers.core.Dense at 0x1963f4ff490>,\n",
       " <keras.layers.core.Dropout at 0x1963f4ff310>,\n",
       " <keras.layers.core.Dense at 0x1963f4c0f10>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6d5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(newnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d39c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kz_ke\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf95644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, None, x_train.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4be72028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - 4s 3ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19644e338b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 40, epochs =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c6168af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 1s 1ms/step - loss: 0.0045 - root_mean_squared_error: 0.0669\n"
     ]
    }
   ],
   "source": [
    "bestval = model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebd21eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporated net, acc: 0.066895, net: [LSTM(100,sigmoid), FC(200, leaky_relu), D(0.100000), FC(1, leaky_relu)]\n"
     ]
    }
   ],
   "source": [
    "factory.incorporate_trained_net(net, bestval, 1, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47f23957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net</th>\n",
       "      <th>accuracy_best_val</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[FC(200, leaky_relu), D(0.000000), FC(1, sigmo...</td>\n",
       "      <td>0.528048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[LSTM(20,relu), LSTM(10,linear), FC(100, tanh)...</td>\n",
       "      <td>0.074497</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[FC(50, linear), FC(1, tanh)]</td>\n",
       "      <td>0.087128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[FC(1, linear)]</td>\n",
       "      <td>0.089298</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[FC(1, relu)]</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 net  accuracy_best_val  \\\n",
       "0  [FC(200, leaky_relu), D(0.000000), FC(1, sigmo...           0.528048   \n",
       "1  [LSTM(20,relu), LSTM(10,linear), FC(100, tanh)...           0.074497   \n",
       "2                      [FC(50, linear), FC(1, tanh)]           0.087128   \n",
       "0                                    [FC(1, linear)]           0.089298   \n",
       "0                                      [FC(1, relu)]           0.074311   \n",
       "\n",
       "   epsilon  iteration  \n",
       "0        1          1  \n",
       "1        1          2  \n",
       "2        1          3  \n",
       "0        1          4  \n",
       "0        1          5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory.replay_dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
